{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5f9be-e656-4718-a7a0-1ff9228f5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch] datasets pandas rouge-score pyrogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76f5717-09dc-4f47-b01a-6411a6e27fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertLMHeadModel, BertTokenizerFast\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\"\n",
    "model_id = \"EleutherAI/gpt-neo-2.7B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, is_decoder=True, output_hidden_states=True).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84be5d8-239b-4eca-baff-d4467aad4ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      For some time after its birth, it grows by gai...\n",
       "1      When the bud on its back starts swelling, a sw...\n",
       "2      After a rainy day, the flower on its back smel...\n",
       "3      The fire on the tip of its tail is a measure o...\n",
       "4      In the rocky mountains where Charmeleon live, ...\n",
       "                             ...                        \n",
       "796    One of the mysterious life-forms known as Ultr...\n",
       "797    One kind of Ultra Beast. Witnesses have seen i...\n",
       "798    This Ultra Beast came from the Ultra Wormhole....\n",
       "799    A dangerous Ultra Beast, it appears to be eati...\n",
       "800                                                    -\n",
       "Name: description, Length: 801, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "# test = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "\n",
    "# test = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "# encodings = tokenizer(\"\\n\\n\".join(test[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5902e39-4911-4cf7-9ca3-ad26dba15ee8",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "346d3971-6222-4e7c-b80f-87ca020916c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_sent = \"Hello, nice to meet you.\"\n",
    "\n",
    "def perplexity(sent):\n",
    "    encodings = tokenizer(sent, return_tensors=\"pt\")\n",
    "\n",
    "    max_length = model.config.max_position_embeddings\n",
    "    stride = 512\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            # https://stackoverflow.com/a/64796860/15557377\n",
    "            action_logits = outputs.logits\n",
    "            probs = torch.softmax(outputs.logits, dim = -1)\n",
    "            sumProb = 0\n",
    "            print(len(probs))\n",
    "            for tensor in probs[0]:\n",
    "                prob = torch.max(tensor)\n",
    "                print(prob)\n",
    "                sumProb += prob\n",
    "            \n",
    "            sent\n",
    "            \n",
    "            # Sum of all actions will equal the length of input as all distributions for each word prediction sum to 1\n",
    "            # == print(len(torch.softmax(outputs.logits, dim = -1)[0])))\n",
    "            # print(torch.softmax(outputs.logits, dim = -1))\n",
    "            \n",
    "            \n",
    "            \n",
    "            # probs = torch.nn.functional.softmax(last_hidden_state[mask_index])\n",
    "\n",
    "            # loss is calculated using CrossEntropyLoss which averages over input tokens.\n",
    "            # Multiply it with trg_len to get the summation instead of average.\n",
    "            # We will take average over all the tokens to get the true average\n",
    "            # in the last step of this example.\n",
    "            neg_log_likelihood = outputs.loss * trg_len\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
    "    return ppl.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "811cd684-4d97-4957-be59-08ed1c4d35e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OI\n",
      "1\n",
      "tensor(0.2614, device='cuda:0')\n",
      "tensor(0.1647, device='cuda:0')\n",
      "tensor(0.7440, device='cuda:0')\n",
      "tensor(0.7174, device='cuda:0')\n",
      "tensor(0.9575, device='cuda:0')\n",
      "tensor(0.3428, device='cuda:0')\n",
      "tensor(0.2337, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.1920857429504395"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(test_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8deb3a-bd88-4abb-bfaa-5e22a1d6427f",
   "metadata": {},
   "source": [
    "# SLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fee1e90-26b0-4f20-8db4-424e724f05fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      For some time after its birth, it grows by gai...\n",
       "1      When the bud on its back starts swelling, a sw...\n",
       "2      After a rainy day, the flower on its back smel...\n",
       "3      The fire on the tip of its tail is a measure o...\n",
       "4      In the rocky mountains where Charmeleon live, ...\n",
       "                             ...                        \n",
       "796    One of the mysterious life-forms known as Ultr...\n",
       "797    One kind of Ultra Beast. Witnesses have seen i...\n",
       "798    This Ultra Beast came from the Ultra Wormhole....\n",
       "799    A dangerous Ultra Beast, it appears to be eati...\n",
       "800                                                    -\n",
       "Name: description, Length: 801, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58eb71d9-d6ba-4522-aa00-5fbef9335536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed from perplexity calculation: https://huggingface.co/docs/transformers/perplexity\n",
    "\n",
    "def sentProb(sent): \n",
    "    encodings = tokenizer(sent, return_tensors=\"pt\")\n",
    "    max_length = model.config.max_position_embeddings\n",
    "    stride = 512\n",
    "    \n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "    \n",
    "    \n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    sentProb = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            # https://stackoverflow.com/a/64796860/15557377\n",
    "            action_logits = outputs.logits\n",
    "            probs = torch.softmax(outputs.logits, dim = -1)\n",
    "            for tensor in probs[0]:\n",
    "                prob = torch.max(tensor)\n",
    "                sentProb += prob\n",
    "            \n",
    "    \n",
    "            # Sum of all actions will equal the length of input as all distributions for each word prediction sum to 1\n",
    "            # == print(len(torch.softmax(outputs.logits, dim = -1)[0])))\n",
    "            # print(torch.softmax(outputs.logits, dim = -1))\n",
    "    sentLen = len(sent)\n",
    "    sentProb = sentProb / sentLen\n",
    "    return sentProb\n",
    "    \n",
    "def slor(sent):\n",
    "    sentP = sentProb(sent)\n",
    "    sumWordProb = 1\n",
    "    ids = tokenizer.encode(sent.lower())\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "    for token in tokens:\n",
    "        sumWordProb = sumWordProb * sentProb(token)\n",
    "    return 1/len(tokens) * ( torch.log(sentP) - torch.log(sumWordProb) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4233d1c-f747-4b13-b44f-2eb7c2fa2528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'Ġsome', 'Ġtime', 'Ġafter', 'Ġits', 'Ġbirth', ',', 'Ġit', 'Ġgrows', 'Ġby', 'Ġgaining', 'Ġnour', 'ishment', 'Ġfrom', 'Ġthe', 'Ġseed', 'Ġon', 'Ġits', 'Ġback', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2507, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(slor(descriptions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffcbbd3-9df4-44ba-b0e4-ffb27f539864",
   "metadata": {},
   "source": [
    "# Error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc39b9a-88b9-43f2-aa33-88257b2b21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     errors\n",
    "# 1 - ------\n",
    "#     tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873691e-9912-4f85-8cdb-43fbe64fa72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade language_tool_python\n",
    "!pip install nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750e9825-97e8-4282-80f5-0835142a6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageToolPublicAPI('en-US')  # use a remote server (automatically set up), language English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ae38b27-a9c3-4100-bc15-0fc757981cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match({'ruleId': 'UPPERCASE_SENTENCE_START', 'message': 'This sentence does not start with an uppercase letter.', 'replacements': ['Helo'], 'offsetInContext': 0, 'context': 'helo darknes my old frend', 'offset': 0, 'errorLength': 4, 'category': 'CASING', 'ruleIssueType': 'typographical', 'sentence': 'helo darknes my old frend'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['darkness', 'darkens', 'darkies'], 'offsetInContext': 5, 'context': 'helo darknes my old frend', 'offset': 5, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'helo darknes my old frend'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['friend', 'trend', 'Fred', 'freed', 'Freud', 'Friend', 'fend', 'fiend', 'frond', 'rend', 'fr end'], 'offsetInContext': 20, 'context': 'helo darknes my old frend', 'offset': 20, 'errorLength': 5, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'helo darknes my old frend'})]\n",
      "5\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def errorRate(sent):\n",
    "    check = tool.check(sent)\n",
    "    numTokens = len(word_tokenize(sent))\n",
    "    numErrors = len(check)\n",
    "    print(check)\n",
    "    print(numTokens)\n",
    "    print(numErrors)\n",
    "    return 1 - float(numErrors) / float(numTokens)\n",
    "\n",
    "errorRate('helo darknes my old frend')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa418c",
   "metadata": {},
   "source": [
    "# Rogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb33acc",
   "metadata": {},
   "source": [
    "### Convert text to ROGUE format and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb736af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrouge import Rouge155\n",
    "\n",
    "r = Rouge155()\n",
    "r.system_dir = 'path/to/system_summaries'\n",
    "r.model_dir = 'path/to/model_summaries'\n",
    "r.system_filename_pattern = 'some_name.(\\d+).txt'\n",
    "r.model_filename_pattern = 'some_name.[A-Z].#ID#.txt'\n",
    "\n",
    "output = r.convert_and_evaluate()\n",
    "print(output)\n",
    "output_dict = r.output_to_dict(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4daca",
   "metadata": {},
   "source": [
    "### Convert summaries to rogue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1226a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rouge155.convert_summaries_to_rouge_format(system_input_dir, system_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fe38e5-7527-483a-b0a8-bcc89bf652b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from pyrouge import Rouge155\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "                      'The quick brown dog jumps on the log.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc6074dc803f43baa6a0a2053c2486e511cb760353685bf60a1fdaf9b997ca08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
